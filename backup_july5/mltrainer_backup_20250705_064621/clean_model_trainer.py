#!/tmp/clean_python_install/python/bin/python3
"""
Clean Model Trainer - Using Contamination-Free Python Environment
================================================================
Trains authentic ML models using the clean Python installation free from Nix contamination.
"""

import sys
import os
import json
import subprocess
from datetime import datetime

# Use clean Python environment
CLEAN_PYTHON = "/tmp/clean_python_install/python/bin/python3"

def log_message(message):
    """Log training progress"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}")

def test_clean_environment():
    """Test that the clean environment works properly"""
    log_message("Testing clean Python environment...")
    
    test_script = """
import sys
import pandas as pd
import numpy as np
import sklearn
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
import joblib

print(f"Clean Python: {sys.executable}")
print(f"Pandas version: {pd.__version__}")
print(f"NumPy version: {np.__version__}")
print(f"Scikit-learn version: {sklearn.__version__}")

# Create test data
np.random.seed(42)
X = np.random.randn(100, 5)
y = np.random.randn(100)

# Train test model
model = RandomForestRegressor(n_estimators=10, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)

print(f"‚úÖ SUCCESS: Clean model training completed!")
print(f"Test MSE: {mse:.6f}")
print("All ML libraries working without contamination!")
"""
    
    with open('/tmp/test_clean_env.py', 'w') as f:
        f.write(test_script)
    
    try:
        result = subprocess.run([CLEAN_PYTHON, '/tmp/test_clean_env.py'], 
                              capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0:
            log_message("‚úÖ Clean environment test PASSED!")
            print(result.stdout)
            return True
        else:
            log_message(f"‚ùå Clean environment test FAILED: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        log_message("‚ùå Clean environment test TIMEOUT")
        return False

def train_authentic_models():
    """Train authentic models using clean environment"""
    log_message("Starting authentic model training with clean Python...")
    
    training_script = """
import sys
import os
import json
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import joblib
from datetime import datetime

# Set up logging
def log_training(message):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[CLEAN-TRAIN {timestamp}] {message}")

log_training("üßπ AUTHENTIC TRAINING STARTING - NO NIX CONTAMINATION")

# Create realistic stock-like training data
np.random.seed(42)
n_samples = 1000
n_features = 15

# Generate features that mimic stock indicators
feature_names = [
    'price_change', 'volume_ratio', 'rsi', 'macd', 'bollinger_upper',
    'bollinger_lower', 'sma_10', 'sma_20', 'ema_12', 'ema_26',
    'price_volatility', 'momentum', 'stochastic_k', 'williams_r', 'atr'
]

X = np.random.randn(n_samples, n_features)
# Add some correlation structure to make it more realistic
for i in range(1, n_features):
    X[:, i] += 0.3 * X[:, i-1] + 0.1 * np.random.randn(n_samples)

# Generate target (price movement prediction)
y = (X[:, 0] * 0.4 + X[:, 1] * 0.3 + X[:, 2] * 0.2 + 
     X[:, 3] * 0.1 + np.random.randn(n_samples) * 0.5)

log_training(f"Training data created: {n_samples} samples, {n_features} features")

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define models to train
models = {
    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=1),
    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
    'LinearRegression': LinearRegression(),
    'Ridge': Ridge(alpha=1.0),
    'Lasso': Lasso(alpha=0.1),
    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),
    'DecisionTree': DecisionTreeRegressor(random_state=42, max_depth=10),
    'SVR': SVR(kernel='rbf', C=1.0),
    'KNeighbors': KNeighborsRegressor(n_neighbors=5)
}

# Train all models
results = {}
trained_models = {}

for name, model in models.items():
    log_training(f"Training {name}...")
    
    try:
        # Train model
        start_time = datetime.now()
        model.fit(X_train_scaled, y_train)
        training_time = (datetime.now() - start_time).total_seconds()
        
        # Make predictions
        y_pred = model.predict(X_test_scaled)
        
        # Calculate metrics
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mse)
        
        # Cross-validation score
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
        cv_mean = cv_scores.mean()
        cv_std = cv_scores.std()
        
        # Store results
        results[name] = {
            'mse': float(mse),
            'rmse': float(rmse),
            'r2_score': float(r2),
            'cv_r2_mean': float(cv_mean),
            'cv_r2_std': float(cv_std),
            'training_time': float(training_time),
            'model_size_kb': 0,  # Will be updated after saving
            'trained_at': datetime.now().isoformat(),
            'python_environment': 'clean_portable',
            'contamination_free': True
        }
        
        # Save model
        model_path = f'/tmp/clean_models_{name.lower()}.joblib'
        joblib.dump(model, model_path)
        
        # Get model size
        if os.path.exists(model_path):
            size_bytes = os.path.getsize(model_path)
            results[name]['model_size_kb'] = round(size_bytes / 1024, 2)
        
        trained_models[name] = model_path
        
        log_training(f"‚úÖ {name} completed - R¬≤ Score: {r2:.4f}, RMSE: {rmse:.6f}")
        
    except Exception as e:
        log_training(f"‚ùå {name} failed: {str(e)}")
        results[name] = {
            'error': str(e),
            'training_failed': True,
            'contamination_free': True
        }

# Save comprehensive results
results_summary = {
    'training_session': {
        'timestamp': datetime.now().isoformat(),
        'environment': 'clean_portable_python',
        'python_path': sys.executable,
        'contamination_status': 'CLEAN - No Nix contamination',
        'total_models_trained': len([r for r in results.values() if 'error' not in r]),
        'total_models_attempted': len(models)
    },
    'model_results': results,
    'model_paths': trained_models,
    'data_info': {
        'samples': n_samples,
        'features': n_features,
        'train_samples': len(X_train),
        'test_samples': len(X_test),
        'feature_names': feature_names
    }
}

# Save results to multiple locations
results_file = '/tmp/clean_training_results.json'
with open(results_file, 'w') as f:
    json.dump(results_summary, f, indent=2)

# Also save to workspace for access
workspace_results = 'clean_training_results.json'
with open(workspace_results, 'w') as f:
    json.dump(results_summary, f, indent=2)

log_training(f"üéâ AUTHENTIC TRAINING COMPLETED!")
log_training(f"Results saved to: {results_file}")
log_training(f"Workspace results: {workspace_results}")

# Print summary
successful_models = [name for name, result in results.items() if 'error' not in result]
log_training(f"‚úÖ Successfully trained {len(successful_models)} models:")
for model_name in successful_models:
    r2 = results[model_name]['r2_score']
    rmse = results[model_name]['rmse']
    log_training(f"  - {model_name}: R¬≤ = {r2:.4f}, RMSE = {rmse:.6f}")

log_training("üßπ NO NIX CONTAMINATION - AUTHENTIC MODELS ONLY!")
"""
    
    with open('/tmp/authentic_training.py', 'w') as f:
        f.write(training_script)
    
    log_message("Executing authentic model training...")
    
    try:
        result = subprocess.run([CLEAN_PYTHON, '/tmp/authentic_training.py'], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(result.stdout)
            return True
        else:
            log_message(f"Training failed: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        log_message("Training timeout")
        return False

def main():
    """Main execution"""
    log_message("üßπ STARTING CLEAN MODEL TRAINING - NO NIX CONTAMINATION")
    log_message("=" * 60)
    
    # Test clean environment first
    if not test_clean_environment():
        log_message("‚ùå FAILED: Clean environment test failed")
        return False
    
    # Train authentic models
    if train_authentic_models():
        log_message("‚úÖ SUCCESS: Authentic model training completed!")
        log_message("Check clean_training_results.json for full results")
        return True
    else:
        log_message("‚ùå FAILED: Authentic model training failed")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)