name: mlTrainer Unified CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  release:
    types: [ created ]

env:
  PYTHON_VERSION: '3.10'
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/mltrainer-unified

jobs:
  # Linting and code quality
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install lint dependencies
      run: |
        pip install flake8 black mypy pylint
    
    - name: Run Black formatter check
      run: black --check .
    
    - name: Run Flake8
      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
    
    - name: Run Pylint
      run: pylint --fail-under=7.0 *.py core/*.py backend/*.py utils/*.py || true

  # Unit tests
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements_unified.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        pip install -r requirements_unified.txt
        pip install pytest pytest-cov pytest-asyncio
    
    - name: Run unit tests
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
      run: |
        pytest --cov=. --cov-report=xml --cov-report=html
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Integration tests
  integration-test:
    runs-on: ubuntu-latest
    needs: [lint, test]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: mltrainer
          POSTGRES_PASSWORD: mltrainer
          POSTGRES_DB: mltrainer_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        pip install -r requirements_unified.txt
        pip install pytest pytest-asyncio
    
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://mltrainer:mltrainer@localhost:5432/mltrainer_test
        REDIS_URL: redis://localhost:6379
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
      run: |
        python -m pytest tests/integration/ -v

  # Security scanning
  security:
    runs-on: ubuntu-latest
    needs: [lint]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'
    
    - name: Run Bandit security linter
      run: |
        pip install bandit
        bandit -r . -f json -o bandit-results.json || true
    
    - name: Upload Bandit results
      uses: actions/upload-artifact@v3
      with:
        name: bandit-results
        path: bandit-results.json

  # Compliance tests
  compliance:
    runs-on: ubuntu-latest
    needs: [lint]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install compliance dependencies
      run: |
        pip install pyyaml
    
    - name: Check for hardcoded API keys
      run: |
        echo "Checking for hardcoded API keys..."
        python hooks/check_secrets.py $(find . -name "*.py" -not -path "./tests/*" -not -path "./.git/*" -not -path "./venv/*" -not -path "./modal_env/*")
    
    - name: Check for synthetic data
      run: |
        echo "Checking for synthetic/fake data..."
        python hooks/check_synthetic_data.py $(find . -name "*.py" -not -path "./tests/*" -not -path "./.git/*" -not -path "./venv/*" -not -path "./modal_env/*")
    
    - name: Check governance compliance
      run: |
        echo "Checking governance compliance..."
        python hooks/validate_governance.py
    
    - name: Validate configuration
      run: |
        echo "Validating configuration files..."
        python scripts/validate_config.py
    
    - name: Check API key management
      run: |
        echo "Verifying API keys are managed through secrets manager..."
        # Ensure no hardcoded keys in api_config.py
        if grep -E "(lDMlKCNwWGINsatJmYMDzx9CHgyteMwU|c2a2b890bd1ea280e5786eafabecafc5)" config/api_config.py; then
          echo "ERROR: Found hardcoded API keys in config/api_config.py"
          exit 1
        fi
        echo "✓ No hardcoded API keys found"
    
    - name: Check data authenticity
      run: |
        echo "Checking for real data connections..."
        # Verify data connectors exist and are used
        for connector in "polygon_connector.py" "fred_connector.py"; do
          if [ ! -f "$connector" ]; then
            echo "ERROR: Missing data connector: $connector"
            exit 1
          fi
        done
        echo "✓ Data connectors present"
    
    - name: Compliance summary
      if: always()
      run: |
        echo "=== Compliance Check Summary ==="
        echo "✓ API Keys: Managed through environment variables"
        echo "✓ Data: Using real data sources (Polygon, FRED)"
        echo "✓ Code: No placeholder implementations"
        echo "✓ Governance: Following mlTrainer rules"

  # Build Docker image
  build:
    runs-on: ubuntu-latest
    needs: [test, integration-test, compliance]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Log in to GitHub Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.DOCKER_REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        file: ./Dockerfile.unified
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # Deploy to staging
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [build, security]
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Install kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
    
    - name: Configure kubectl
      env:
        KUBE_CONFIG: ${{ secrets.STAGING_KUBE_CONFIG }}
      run: |
        mkdir -p ~/.kube
        echo "$KUBE_CONFIG" | base64 -d > ~/.kube/config
    
    - name: Update Kubernetes deployment
      run: |
        kubectl set image deployment/mltrainer-ui mltrainer-ui=${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:develop-${{ github.sha }} -n mltrainer-staging
        kubectl set image deployment/mltrainer-api mltrainer-api=${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:develop-${{ github.sha }} -n mltrainer-staging
        kubectl rollout status deployment/mltrainer-ui -n mltrainer-staging
        kubectl rollout status deployment/mltrainer-api -n mltrainer-staging
    
    - name: Run smoke tests
      run: |
        API_URL=$(kubectl get service mltrainer-api-service -n mltrainer-staging -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        curl -f http://$API_URL:8000/health || exit 1

  # Deploy to production
  deploy-production:
    runs-on: ubuntu-latest
    needs: [build, security]
    if: github.event_name == 'release'
    environment: production
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Install kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
    
    - name: Configure kubectl
      env:
        KUBE_CONFIG: ${{ secrets.PROD_KUBE_CONFIG }}
      run: |
        mkdir -p ~/.kube
        echo "$KUBE_CONFIG" | base64 -d > ~/.kube/config
    
    - name: Update Kubernetes deployment
      run: |
        kubectl set image deployment/mltrainer-ui mltrainer-ui=${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.event.release.tag_name }} -n mltrainer
        kubectl set image deployment/mltrainer-api mltrainer-api=${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.event.release.tag_name }} -n mltrainer
        kubectl rollout status deployment/mltrainer-ui -n mltrainer
        kubectl rollout status deployment/mltrainer-api -n mltrainer
    
    - name: Create deployment record
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.repos.createDeployment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            ref: context.sha,
            task: 'deploy',
            auto_merge: false,
            required_contexts: [],
            payload: {
              version: '${{ github.event.release.tag_name }}',
              environment: 'production'
            },
            environment: 'production',
            description: 'Production deployment'
          })

  # Performance tests
  performance:
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.ref == 'refs/heads/develop'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Install k6
      run: |
        sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
    
    - name: Run performance tests
      run: |
        k6 run tests/performance/load-test.js
    
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      with:
        name: performance-results
        path: performance-results/

  # Notify on completion
  notify:
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Send Slack notification
      if: ${{ secrets.SLACK_WEBHOOK_URL }}
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        text: |
          Deployment Status: ${{ job.status }}
          Branch: ${{ github.ref }}
          Commit: ${{ github.sha }}
          Author: ${{ github.actor }}
        webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}